# ğŸª Carnival Wars - Price Prediction

[![HackerEarth](https://img.shields.io/badge/HackerEarth-ML%20Challenge-blue)](https://www.hackerearth.com/challenges/competitive/hackerearth-machine-learning-challenge-predict-selling-price/)
[![Python](https://img.shields.io/badge/Python-3.7%2B-blue)](https://www.python.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

> A high-performing machine learning solution that placed in the **Top 60 globally** in the HackerEarth **Carnival Wars Machine Learning Challenge**. This project showcases end-to-end regression modeling, advanced ensemble techniques, and real-time deployment with Streamlit.

---

## ğŸ¥ Demo

### ğŸ”¹ Single Product Prediction

Predict price via a clean UI using dropdowns and numeric inputs.

![Single Prediction](./singleprocessing.gif)

### ğŸ”¸ Batch Prediction

Upload a `.csv` and get results in tabular format with download support.

![Batch Prediction](./batchprocessing.gif)

---

## ğŸ† Competition Performance

This solution secured a **Top 60 rank** in the [HackerEarth Carnival Wars ML Challenge](https://www.hackerearth.com/challenges/competitive/hackerearth-machine-learning-challenge-predict-selling-price/), a global challenge focused on price prediction for carnival products.

![Leaderboard](./leaderboard.jpg)

* ğŸ† **Final Rank**: 60
* ğŸ“Š **Score**: 91.49646
* ğŸ’ª **Margin from Top**: \~0.53%

<p align="center">
  <img src="./leaderboard.jpg" alt="Leaderboard Snapshot" width="600"/>
</p>

---

## ğŸ“‹ Table of Contents

* [Overview](#-overview)
* [Dataset](#-dataset)
* [Installation](#-installation)
* [Project Structure](#-project-structure)
* [Methodology](#-methodology)
* [Results](#-results)
* [Web Application](#-web-application)
* [Getting Started](#-getting-started)
* [Contributing](#-contributing)
* [License](#-license)

---

## ğŸŒŸ Overview

ğŸ¯ **Challenge Theme**
Boo yeah, itâ€™s the holiday season again! In a countryside carnival filled with festive joy, the challenge was to help local stall owners predict optimal selling prices for their products. Inspired by the real-world dynamics of seasonal shopping, participants were asked to step into the shoes of data scientists and optimize pricing strategies for higher revenue.

ğŸ§  **Objective**
Build a regression model that accurately predicts product selling prices using features such as product category, market type, grade, demand, pricing limits, available discounts, and time-based attributes.

ğŸ› ï¸ **Why This Matters**

* Reinforces fundamental regression concepts
* Offers real-world price prediction use case
* Encourages thoughtful feature engineering
* Boosts understanding of production-ready modeling through deployment

> This challenge was not only a technical endeavor but a way to apply machine learning for economic upliftment of small-scale vendors â€” a perfect blend of impact and innovation.

## ğŸ“Š Dataset

* Product category, loyalty, and stall metadata
* Historical price data (min, max, charges)
* Stock availability date
* Demand and grade classification

## ğŸ› ï¸ Installation

```bash
pip install -r requirements.txt
```

Or manually:

```bash
pip install numpy pandas matplotlib seaborn scikit-learn catboost lightgbm xgboost streamlit plotly
```

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ model_training.py           # Training script
â”œâ”€â”€ Dataset/
â”‚   â”œâ”€â”€ test.csv
â”‚   â””â”€â”€ train.csv
â”œâ”€â”€ app.py                      # Streamlit frontend
â”œâ”€â”€ resources/
â”‚   â””â”€â”€ stacked_model.pkl       # Trained ensemble model
â”œâ”€â”€ resources/                  # Saved model and leaderboard image
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ Methodology

### Data Preprocessing

* Extracted and encoded date features (day, month, weekofyear)
* Generated cyclic features with sine/cosine transforms
* Added missing value flags and log-scaled charges
* One-hot encoding for product categories

### Modeling and Ensembling

* **Base Models**: CatBoost, LightGBM, XGBoost, Decision Trees
* **Meta-Model**: Linear Regressor on predictions of base models
* **Cross-validation**: K-Fold based performance validation
* **GPU Acceleration** enabled for major libraries

## ğŸ‘ï¸ Results

* âœ… Final Model: Voting ensemble + meta-regressor
* ğŸ“‰ Error reduced by \~9% over best single model
* âš¡ Fast training with automatic GPU detection

## ğŸ’» Web Application

Built with Streamlit for real-time usage and batch predictions.

## âš™ï¸ Core Snippet

```python
USE_GPU = has_nvidia_gpu()
DEVICE = "GPU" if USE_GPU else "CPU"

MODELS = {
    'catboost': CatBoostRegressor(task_type=DEVICE.lower()),
    'lightgbm': LGBMRegressor(device=DEVICE.lower()),
    'xgboost': XGBRegressor(tree_method='gpu_hist' if USE_GPU else 'auto')
}
```

## ğŸš€ Getting Started

```bash
git clone https://github.com/omkarbhad/Carnival-Wars-Hackathon.git
cd Carnival-Wars-Hackathon
pip install -r requirements.txt
# If needed: unzip resources.zip -d .  # For Linux/Mac or use Expand-Archive on Windows
```

To train model:

```bash
python model_training.py
```

To launch demo:

```bash
streamlit run app.py
```

## ğŸ¤ Contributing

Feel free to open issues, submit pull requests, or suggest enhancements.

## ğŸ“„ License

This project is licensed under the MIT License. See [LICENSE](LICENSE) for details.
